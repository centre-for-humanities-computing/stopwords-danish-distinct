{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DistinctStopwords import DistinctStopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find distinct stopwords in Danish\n",
    "DA = DistinctStopwords(target_lang='da',\n",
    "                           # limit output to 100 words\n",
    "                           n_stopwords=100,\n",
    "                           # keep Swedish and Norwegian words in\n",
    "                           keep_lang=['sv', 'no'],\n",
    "                           # filter out all other languages that we consider\n",
    "                           unwanted_lang=\"all\",\n",
    "                           # remove 50k most frequent\n",
    "                           unwanted_threshold=50000,\n",
    "                           # get rid of everything in English\n",
    "                           feared_lang='en',\n",
    "                           # save as\n",
    "                           output_path='wordlists/M8_DA.txt')\n",
    "\n",
    "# train\n",
    "DA.get_distinct_stopwords()\n",
    "DA.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find distinct stopwords in Swedish\n",
    "SV = DistinctStopwords(target_lang='sv',\n",
    "                           # limit output to 100 words\n",
    "                           n_stopwords=100,\n",
    "                           # keep Swedish and Norwegian words in\n",
    "                           keep_lang=['da', 'no'],\n",
    "                           # filter out all other languages that we consider\n",
    "                           unwanted_lang=\"all\",\n",
    "                           # remove 50k most frequent\n",
    "                           unwanted_threshold=50000,\n",
    "                           # get rid of everything in English\n",
    "                           feared_lang='en',\n",
    "                           # save as\n",
    "                           output_path='wordlists/M8_SV.txt')\n",
    "\n",
    "# train\n",
    "SV.get_distinct_stopwords()\n",
    "SV.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find distinct stopwords in Norwegian\n",
    "NO = DistinctStopwords(target_lang='no',\n",
    "                           # limit output to 100 words\n",
    "                           n_stopwords=100,\n",
    "                           # keep Swedish and Norwegian words in\n",
    "                           keep_lang=['da', 'sv'],\n",
    "                           # filter out all other languages that we consider\n",
    "                           unwanted_lang=\"all\",\n",
    "                           # remove 50k most frequent\n",
    "                           unwanted_threshold=50000,\n",
    "                           # get rid of everything in English\n",
    "                           feared_lang='en',\n",
    "                           # save as\n",
    "                           output_path='wordlists/M8_NO.txt')\n",
    "\n",
    "# train\n",
    "NO.get_distinct_stopwords()\n",
    "NO.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find distinct stopwords in the small Nynorsk set\n",
    "NO_NN = DistinctStopwords(target_lang='no_nn',\n",
    "                           # limit output to 100 words\n",
    "                           n_stopwords=100,\n",
    "                           # keep Swedish and Norwegian words in\n",
    "                           keep_lang=['da', 'sv', 'no'],\n",
    "                           # filter out all other languages that we consider\n",
    "                           unwanted_lang=\"all\",\n",
    "                           # remove 50k most frequent\n",
    "                           unwanted_threshold=50000,\n",
    "                           # get rid of everything in English\n",
    "                           feared_lang='en',\n",
    "                           # save as\n",
    "                           output_path='wordlists/M8_NO_NN.txt')\n",
    "\n",
    "# train\n",
    "NO_NN.get_distinct_stopwords()\n",
    "NO_NN.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine all into a long list\n",
    "# extract words\n",
    "da_words = [word for word in DA.da_export['word']]\n",
    "sv_words = [word for word in SV.da_export['word']]\n",
    "no_words = [word for word in NO.da_export['word']]\n",
    "no_nn_words = [word for word in NO_NN.da_export['word']]\n",
    "\n",
    "danosv_words = da_words + sv_words + no_words + no_nn_words\n",
    "\n",
    "# keep only unique\n",
    "danosv = list(dict.fromkeys(danosv_words))\n",
    "\n",
    "# export\n",
    "with open(\"M8_danosv_augumented.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(danosv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (virtualenv_synset)",
   "language": "python",
   "name": "virtualenv_synset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
